import math
import numpy as np
from typing import List, Optional

from waffles.data_classes.WaveformSet import WaveformSet

import waffles.utils.check_utils as wuc

from waffles.Exceptions import GenerateExceptionMessage

from hdf5libs import HDF5RawDataFile

# import daqdataformats
from daqdataformats import FragmentType
from rawdatautils.unpack.daphne import *
from rawdatautils.unpack.utils import *

import detdataformats
import fddetdataformats

import os
import click
import subprocess
import stat
from array import array

from tqdm import tqdm
from multiprocessing import Pool, current_process, cpu_count

from waffles.data_classes.Waveform import Waveform
from waffles.data_classes.WaveformSet import WaveformSet

# these functions should probably have a shared location, since they are used elsewhere...
map_id = {'104': [1, 2, 3, 4], '105': [5, 6, 7, 9], '107': [
    10, 8], '109': [11], '111': [12], '112': [13], '113': [14]}


def find_endpoint(map_id, target_value):
    for key, value_list in map_id.items():
        if target_value in value_list:
            return key


def split_list(original_list, n_splits):
    avg = len(original_list) / float(n_splits)
    out = []
    last = 0.0

    while last < len(original_list):
        out.append(original_list[int(last):int(last + avg)])
        last += avg

    return out


def check_PDS(raw_file):
    h5_file = HDF5RawDataFile(raw_file)
    record = list(h5_file.get_all_record_ids())[0]
    gid = list(h5_file.get_geo_ids_for_subdetector(
        record, detdataformats.DetID.string_to_subdetector('HD_PDS')))
    if len(gid) == 0:
        output = False
    else:
        output = True
    return output


def extract_fragment_info(frag, trig):
    frag_id = str(frag).split(' ')[3][:-1]
    frh = frag.get_header()
    trh = trig.get_header()

    scr_id = frh.element_id.id
    fragType = frh.fragment_type
    window_begin_dts = frh.window_begin

    trigger_timestamp = trh.trigger_timestamp
    daq_pretrigger = window_begin_dts - trigger_timestamp

    threshold = -1
    baseline = -1
    trigger_sample_value = -1

    if fragType == FragmentType.kDAPHNE.value:  # For self trigger
        trigger = 'self_trigger'
        frame_obj = fddetdataformats.DAPHNEFrame
        daphne_headers = [frame_obj(frag.get_data(
            iframe*frame_obj.sizeof())).get_header() for iframe in range(get_n_frames(frag))]
        # [header.threshold for header in daphne_headers]
        threshold = daphne_headers[0].threshold
        baseline = [header.baseline for header in daphne_headers]
        trigger_sample_value = [
            header.trigger_sample_value for header in daphne_headers]

        timestamps = np_array_timestamp(frag)
        adcs = np_array_adc(frag)
        channels = np_array_channels(frag)

    elif fragType == 13:  # For full_stream
        trigger = 'full_stream'
        timestamps = np_array_timestamp_stream(frag)
        adcs = np_array_adc_stream(frag)
        channels = np_array_channels_stream(frag)[0]

    return trigger, frag_id, scr_id, channels, adcs, timestamps, threshold, baseline, trigger_sample_value, daq_pretrigger


def filepath_is_hdf5_file_candidate(filepath: str) -> bool:
    """
    This function returns True if the given file path points
    to a file which exists and whose extension is '.hdf5' or '.h5'. It
    returns False if else.

    Parameters
    ----------
    filepath : str
        The file path to be checked.

    Returns
    ----------
    bool
    """

    if os.path.isfile(filepath):
        if filepath.endswith('.hdf5') or filepath.endswith('.h5'):
            return True

    return False


def WaveformSet_from_hdf5_files(filepath_list: List[str] = [],
                                read_full_streaming_data: bool = False,
                                folderpath: Optional[str] = None) -> WaveformSet:
    """
    Alternative initializer for a WaveformSet object that reads waveforms directly from hdf5 files. 
    The WaveformSet object made from each hdf5 file is combined into a single WaveformSet object.

    Parameters
    ----------
    folderpath : str
        If given, then the value given to the 'filepath_list'
        parameter is ignored, and the list of filepaths to be 
        read is generated by listing all the files in the given 
        folder.
    filepath : str
        Path to the hdf5 file to be read. 
    read_full_streaming_data : bool
        If True (resp. False), then only the waveforms for which 
        the 'is_fullstream' parameter in the fragment has a 
        value equal to True (resp. False) will be considered.
    """
    if folderpath is not None:

        if not os.path.isdir(folderpath):
            raise Exception(GenerateExceptionMessage(1,
                                                     'WaveformSet_from_hdf5_files()',
                                                     f"The given folderpath ({folderpath}) is not a valid directory."))

        valid_filepaths = [os.path.join(folderpath, filename)
                           for filename in os.listdir(folderpath)
                           if filepath_is_hdf5_file_candidate(os.path.join(folderpath, filename))]
    else:
        valid_filepaths = [filepath
                           # Remove possible duplicates
                           for filepath in set(filepath_list)
                           if filepath_is_hdf5_file_candidate(filepath)]
    output = WaveformSet_from_hdf5_file(
        filepath_list[0], read_full_streaming_data)

    for filepath in filepath_list[1:]:
        aux = WaveformSet_from_hdf5_file(filepath, read_full_streaming_data)
        output.merge(aux)

    return output


def WaveformSet_from_hdf5_file(filepath: str,
                               read_full_streaming_data: bool = False) -> WaveformSet:
    """
    Alternative initializer for a WaveformSet object that reads waveforms directly from hdf5 files.

    Parameters
    ----------
    filepath : str
        Path to the hdf5 file to be read. 
    read_full_streaming_data : bool
        If True (resp. False), then only the waveforms for which 
        the 'is_fullstream' parameter in the fragment has a 
        value equal to True (resp. False) will be considered.
    """

    det = 'HD_PDS'
    h5_file = HDF5RawDataFile(filepath)
    run_date = h5_file.get_attribute('creation_timestamp')

    run_id = filepath.split('_')[3]
    run_flow = filepath.split('_')[4]
    datawriter = dataflow = filepath.split('_')[6]
    # run_numb = (filepath.split('_')[7]).split('.')[0]
    run_numb = int((filepath.split('_')[2]).strip('run'))
    print('run_numb=', run_numb)

    waveforms = []
    active_endpoints = set()
    threshold_list = []

    records = h5_file.get_all_record_ids()
    # print(f'total number of records = {len(records)}')
    for i, r in tqdm(enumerate(records)):
        pds_geo_ids = list(h5_file.get_geo_ids_for_subdetector(
            r, detdataformats.DetID.string_to_subdetector(det)))

        for gid in pds_geo_ids:
            frag = h5_file.get_frag(r, gid)
            trig = h5_file.get_trh(r)

            trigger, frag_id, scr_id, channels_frag, adcs_frag, timestamps_frag, threshold_frag, baseline_frag, trigger_sample_value_frag, daq_pretrigger_frag = extract_fragment_info(
                frag, trig)

            endpoint = int(find_endpoint(map_id, scr_id))
            channels_frag = 100 * int(endpoint) + channels_frag

            # if debug:
            #    print("GEO ID:", gid)
            #    print("FRAG ID:", frag_id)
            #    print("EP:", endpoint)
            #    print("CH:", channels)
            #    print("ADCS:", adcs)

            if trigger == 'full_stream':
                adcs_frag = adcs_frag.transpose()
                timestamps_frag = [timestamps_frag[0]] * len(channels_frag)
                baseline_frag = [-1] * len(channels_frag)
                trigger_sample_value_frag = [-1] * len(channels_frag)
                is_fullstream_frag = [True] * len(channels_frag)
            elif trigger == 'self_trigger':
                is_fullstream_frag = [False] * len(channels_frag)

            if endpoint not in active_endpoints:
                active_endpoints.add(endpoint)
                threshold_list.append(threshold_frag)

            for index, ch in enumerate(channels_frag):

                adcs = []
                adcs = adcs_frag[index]
                # for value in adcs_frag[index]:
                #    #adcs.push_back(int(value))
                #    adcs.append(int(value))
                if read_full_streaming_data == is_fullstream_frag[index]:
                    waveforms.append(Waveform(timestamps_frag[index],
                                              16.,    # time_step_ns
                                              np.array(adcs),
                                              run_numb,
                                              r[0],
                                              endpoint,
                                              ch,
                                              time_offset=0))

    return WaveformSet(*waveforms)
