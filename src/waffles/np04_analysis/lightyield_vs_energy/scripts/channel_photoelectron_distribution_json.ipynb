{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009fb478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving from many .json files with all processed photoelectrons information produced by jupyternotebook_esecuzione.ipynb\n",
    "# to a single .json file for each energy\n",
    "# with pe signal info channel by channel (both APA1 and APA2)\n",
    "\n",
    "# The signal selection is done by looking at the APA 1 pe threshold (i choose it as the crossing point between the langauss and gaussian fit of the APA1 mean pe distribution)\n",
    "\n",
    "# The new dictionary is saved as channel_data.json in the output folder (channel_study), energy per energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4f2c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import waffles.np04_analysis.lightyield_vs_energy.scripts.utils as utils_module\n",
    "from waffles.np04_analysis.lightyield_vs_energy.scripts.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b9d455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Energy to analyze\n",
    "energy = 7\n",
    "\n",
    "energy_dict = {1: 0, 2: 118, 3: 113, 5: 174, 7: 238} # I'm using the intersection between the fitted langaauss and gaussian of the apa1 mean pe distribution\n",
    "apa_mean_pe_threshold = energy_dict[energy]\n",
    "\n",
    "input_folder = f\"/afs/cern.ch/work/a/anbalbon/private/waffles/src/waffles/np04_analysis/lightyield_vs_energy/output/apa1_vs_apa2\"\n",
    "\n",
    "apa12_energy_folder = f\"{input_folder}/{energy}GeV\"\n",
    "output_folder= f\"{apa12_energy_folder}/channel_study\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523c231e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_energy_json_dict(energy: int, apa12_folder: str, output_dir: str) -> dict:\n",
    "    \"\"\"\n",
    "    Legge tutti i JSON 'photoelectron_dic_{energy}GeV.json' nelle sottocartelle\n",
    "    '{start}_to_{stop}' di {energy}GeV e li raccoglie in un unico dizionario:\n",
    "\n",
    "        merged_dict[\"start_to_stop\"] = contenuto_json\n",
    "\n",
    "    Inoltre concatena tutti i files_read.txt in un unico file\n",
    "    'files_read_ALL.txt' dentro output_dir.\n",
    "    \"\"\"\n",
    "\n",
    "    energy_folder = Path(apa12_folder)\n",
    "\n",
    "    if not energy_folder.exists():\n",
    "        raise FileNotFoundError(f\"Folder {energy_folder} doesn't exist\")\n",
    "\n",
    "    merged_dict = {}\n",
    "    all_txt_lines = []\n",
    "\n",
    "    for subfolder in sorted(energy_folder.iterdir()):\n",
    "        # solo directory valide\n",
    "        if not subfolder.is_dir():\n",
    "            continue\n",
    "\n",
    "        # solo cartelle tipo {start}_to_{stop}\n",
    "        if \"_to_\" not in subfolder.name:\n",
    "            continue\n",
    "\n",
    "        json_file = subfolder / f\"photoelectron_dic_{energy}GeV.json\"\n",
    "        txt_file = subfolder / \"files_read.txt\"\n",
    "\n",
    "        # ---------- JSON ----------\n",
    "        if not json_file.exists():\n",
    "            print(f\"⚠️ Missing JSON file: {json_file}\")\n",
    "            continue\n",
    "\n",
    "        with json_file.open(\"r\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        # salva il JSON sotto il nome della cartella\n",
    "        merged_dict[subfolder.name] = data\n",
    "\n",
    "        # ---------- TXT ----------\n",
    "        if txt_file.exists():\n",
    "            with txt_file.open(\"r\") as f:\n",
    "                # pulisce newline e mantiene ordine\n",
    "                all_txt_lines.extend(line.rstrip() + \"\\n\" for line in f)\n",
    "        else:\n",
    "            print(f\"⚠️ Missing TXT file: {txt_file}\")\n",
    "\n",
    "    if not merged_dict:\n",
    "        raise RuntimeError(f\"No JSON files found for energy = {energy}\")\n",
    "\n",
    "    # ---------- SCRITTURA FILE TXT UNICO ----------\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # rimuove eventuali duplicati mantenendo l'ordine\n",
    "    all_txt_lines = list(dict.fromkeys(all_txt_lines))\n",
    "\n",
    "    output_txt = output_dir / \"files_read_ALL.txt\"\n",
    "    with output_txt.open(\"w\") as f:\n",
    "        f.writelines(all_txt_lines)\n",
    "\n",
    "    print(f\"✅ Written merged txt file: {output_txt}\")\n",
    "    print(f\"✅ Total txt lines: {len(all_txt_lines)}\")\n",
    "    print(f\"✅ Total JSON blocks: {len(merged_dict)}\\n\")\n",
    "\n",
    "    return merged_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c6e237",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dict = load_energy_json_dict(energy, apa12_energy_folder, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36744358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUMMARY OF THE DICTIONARY STRUCTURE\n",
    "\n",
    "print(\"\\nSUMMARY OF THE DICTIONARY STRUCTURE\\n\")\n",
    "\n",
    "print(f\"merged_dict keys:\\n{list(merged_dict.keys())}\\n\")\n",
    "print(f\"merged_dict['0_to_10'] keys:\\n{list(merged_dict['0_to_10'].keys())}\\n\")\n",
    "print(f\"merged_dict['0_to_10']['1'] keys:\\n{list(merged_dict['0_to_10']['1'].keys())}\\n\")\n",
    "print(f\"merged_dict['0_to_10']['1']['channel_dic'] is a list of dict keys\\n\")\n",
    "print(f\"merged_dict['0_to_10']['1']['channel_dic'][0] keys: endpoints\\n{list(merged_dict['0_to_10']['1']['channel_dic'][0].keys())}\\n\")\n",
    "print(f\"merged_dict['0_to_10']['1']['channel_dic'][0]['104'] keys: channels\\n{list(merged_dict['0_to_10']['1']['channel_dic'][0]['104'].keys())}\\n\")\n",
    "print(f\"merged_dict['0_to_10']['1']['channel_dic'][0]['104']['0'] keys:\\n{list(merged_dict['0_to_10']['1']['channel_dic'][0]['104']['0'].keys())}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c9179b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECTING TRIGGERS INDEXES WHERE APA1 MEAN PE > THRESHOLD\n",
    "\n",
    "dic_trigger_index = {}\n",
    "for _to_, to_dict in merged_dict.items(): # looking at each \"0_to_10\", \"10_to_20\", ...\n",
    "    index_list = []\n",
    "    for i, trigger_mean_pe in enumerate(to_dict['1']['mean']): # looking at each trigger\n",
    "        try:\n",
    "            if trigger_mean_pe > apa_mean_pe_threshold: # checking if the mean photoelectrons in APA1 is above threshold\n",
    "                index_list.append(i)\n",
    "        except:\n",
    "            continue\n",
    "    dic_trigger_index[_to_] = index_list # saving the list of trigger indexes that passed the threshold for this \"_to_\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbb145f",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_data = {104: {0: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 1: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 2: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 3: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 4: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 5: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 6: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 7: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []},\n",
    "                    10: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 11: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 12: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 13: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 14: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 15: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 16: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 17: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}},\n",
    "            105: {0: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 1: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 2: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 3: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 4: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 5: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 6: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 7: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []},\n",
    "                    10: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 12: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 15: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 17: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 21: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 23: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 24: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 26: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}},\n",
    "            107: {0: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 2: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 5: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 7: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []},\n",
    "                    10: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 12: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 15: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 17: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}},\n",
    "            109: {0: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 1: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 2: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 3: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 4: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 5: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 6: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 7: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []},\n",
    "                    10: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 11: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 12: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 13: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 14: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 15: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 16: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 17: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []},\n",
    "                    20: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 21: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 22: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 23: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 24: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 25: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 26: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 27: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []},\n",
    "                    30: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 31: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 32: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 33: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 34: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 35: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 36: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 37: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []},\n",
    "                    40: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 41: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 42: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 43: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 44: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 45: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 46: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 47: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}},\n",
    "            111: {0: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 1: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 2: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 3: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 4: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 5: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 6: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 7: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []},\n",
    "                    10: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 11: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 12: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 13: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 14: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 15: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 16: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 17: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []},\n",
    "                    20: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 21: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 22: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 23: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 24: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 25: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 26: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 27: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []},\n",
    "                    30: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 31: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 32: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 33: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 34: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 35: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 36: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 37: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []},\n",
    "                    40: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 41: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 42: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 43: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 44: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 45: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 46: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 47: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}},\n",
    "            112: {0: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 1: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 2: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 3: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 4: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 5: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 6: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 7: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []},\n",
    "                    10: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 11: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 12: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 13: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 14: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 15: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 16: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 17: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []},\n",
    "                    20: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 21: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 22: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 23: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 24: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 25: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 26: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 27: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []},\n",
    "                    30: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 31: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 32: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 33: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 34: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 35: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 36: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 37: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []},\n",
    "                    40: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 42: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 45: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 47: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}},\n",
    "            113: {0: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 2: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 5: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}, 7: {'n_pe' : [], 'e_n_pe':  [], 'trigger time' : [], 'trigger index' : []}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4188bf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRAPOLATING SINGLE CHANNEL PHOTOELECTRON INFORMATION  \n",
    "\n",
    "for _to_, index_list in dic_trigger_index.items(): # looking at each \"0_to_10\", \"10_to_20\", ...\n",
    "    for index in index_list:\n",
    "        # accessing channel_dic, \"index\" element containg all triggered channels for that beam trigger\n",
    "        for apa in ['1', '2']: # looking at APA1 and APA2\n",
    "            for end, end_dic in merged_dict[_to_][str(apa)][\"channel_dic\"][index].items(): # looking at each endpoint\n",
    "                for ch, ch_data in end_dic.items(): # looking at each channel\n",
    "                    channel_data[int(end)][int(ch)]['n_pe'].append(ch_data['n_pe'])\n",
    "                    channel_data[int(end)][int(ch)]['e_n_pe'].append(ch_data['e_n_pe'])\n",
    "                    channel_data[int(end)][int(ch)]['trigger index'].append(index)\n",
    "                    channel_data[int(end)][int(ch)]['trigger time'].append(merged_dict[_to_]['trigger time'][index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18350076",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{output_folder}/channels_data.json\", \"w\") as f:\n",
    "    json.dump(channel_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fd1c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print output\n",
    "my_endpoint = 112\n",
    "my_channel = 35\n",
    "print(len(channel_data[int(my_endpoint)][int(my_channel)]['n_pe']))\n",
    "print(channel_data[int(my_endpoint)][int(my_channel)]['n_pe'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "waffles_NEW",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
