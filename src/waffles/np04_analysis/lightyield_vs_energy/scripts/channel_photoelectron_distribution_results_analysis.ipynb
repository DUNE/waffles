{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis of results from channel_photoelectron_distribution.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import waffles.np04_analysis.lightyield_vs_energy.scripts.utils as utils_module\n",
    "from waffles.np04_analysis.lightyield_vs_energy.scripts.utils import *\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\n",
    "    'font.size': 10,\n",
    "    'axes.titlesize': 13,\n",
    "    'axes.labelsize': 13,\n",
    "    'xtick.labelsize': 10,\n",
    "    'ytick.labelsize': 10,\n",
    "    'legend.fontsize': 10,\n",
    "    'figure.dpi': 300,  \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_array(x):\n",
    "    if isinstance(x, np.ndarray):\n",
    "        return x\n",
    "    elif isinstance(x, list):\n",
    "        return np.array(x, dtype=float)\n",
    "    elif isinstance(x, str):\n",
    "        # Rimuove le parentesi quadre e sostituisce le virgole con spazi, poi splitta\n",
    "        clean_str = x.replace('[', '').replace(']', '').replace(',', ' ')\n",
    "        return np.array([float(i) for i in clean_str.split()])\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported type: {type(x)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = \"/afs/cern.ch/work/a/anbalbon/private/waffles/src/waffles/np04_analysis/lightyield_vs_energy/output/single_channels_study\"\n",
    "output_folder = input_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrapolating information about photoelectron distributions fits from json file\n",
    "\n",
    "with open(f\"{input_folder}/PE_study_results.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "for apa, apa_dict in data.items():\n",
    "    all_channels = {\"1\":[], \"2\":[], \"3\":[], \"5\":[], \"7\":[]}\n",
    "    all_endpoint = {\"1\":[], \"2\":[], \"3\":[], \"5\":[], \"7\":[]}\n",
    "    all_apa = {\"1\":[], \"2\":[], \"3\":[], \"5\":[], \"7\":[]}\n",
    "    all_params_gaussian = {\"1\":[], \"2\":[], \"3\":[], \"5\":[], \"7\":[]}\n",
    "    all_eparams_gaussian = {\"1\":[], \"2\":[], \"3\":[], \"5\":[], \"7\":[]}\n",
    "    all_mu_gaussian = {\"1\":[], \"2\":[], \"3\":[], \"5\":[], \"7\":[]}\n",
    "    all_emu_gaussian = {\"1\":[], \"2\":[], \"3\":[], \"5\":[], \"7\":[]}\n",
    "\n",
    "    all_params_langauss = {\"1\":[], \"2\":[], \"3\":[], \"5\":[], \"7\":[]}\n",
    "    all_eparams_langauss = {\"1\":[], \"2\":[], \"3\":[], \"5\":[], \"7\":[]}\n",
    "    all_peak_langauss = {\"1\":[], \"2\":[], \"3\":[], \"5\":[], \"7\":[]}\n",
    "    all_epeak_langauss = {\"1\":[], \"2\":[], \"3\":[], \"5\":[], \"7\":[]}\n",
    "\n",
    "    for end, end_dict in apa_dict.items():\n",
    "        for ch, ch_dict in end_dict.items():\n",
    "            for e in ['1', '2', '3', '5', '7']:\n",
    "                try:\n",
    "                    all_params_gaussian[e].append(ch_dict[e]['gaussian']['params'])\n",
    "                    all_eparams_gaussian[e].append(ch_dict[e]['gaussian']['eparams'])\n",
    "                    all_mu_gaussian[e].append(ch_dict[e]['gaussian']['mu'])\n",
    "                    all_emu_gaussian[e].append(ch_dict[e]['gaussian']['emu'])\n",
    "\n",
    "                    all_params_langauss[e].append(ch_dict[e]['langauss']['params'])\n",
    "                    all_eparams_langauss[e].append(ch_dict[e]['langauss']['eparams'])\n",
    "                    all_peak_langauss[e].append(ch_dict[e]['langauss']['peak'])\n",
    "                    all_epeak_langauss[e].append(ch_dict[e]['langauss']['epeak'])\n",
    "\n",
    "                except KeyError:\n",
    "                    all_params_gaussian[e].append([])\n",
    "                    all_eparams_gaussian[e].append([])\n",
    "                    all_mu_gaussian[e].append([])\n",
    "                    all_emu_gaussian[e].append([])\n",
    "\n",
    "                    all_params_langauss[e].append([])\n",
    "                    all_eparams_langauss[e].append([])\n",
    "                    all_peak_langauss[e].append([])\n",
    "                    all_epeak_langauss[e].append([])\n",
    "                \n",
    "                all_channels[e].append(ch)\n",
    "                all_endpoint[e].append(end)\n",
    "                all_apa[e].append(apa)\n",
    "\n",
    "\n",
    "print(all_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrapolating information about linear fit from csv file\n",
    "'''Visibility information channel by channel'''\n",
    "\n",
    "df = pd.read_csv(f\"{input_folder}/PE_study_results.csv\")\n",
    "\n",
    "df_visibility = pd.read_csv(\"/afs/cern.ch/work/a/anbalbon/private/waffles/src/waffles/np04_analysis/lightyield_vs_energy/data/visibility_arapuca_60r.csv\")\n",
    "\n",
    "df = df.merge(\n",
    "    df_visibility[['vis','endpoint','DAQ_ch']],\n",
    "    left_on=['Endpoint','Channel'],\n",
    "    right_on=['endpoint','DAQ_ch'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "for col in ['Gaussian params', 'Langauss params']:\n",
    "    df[col] = df[col].apply(lambda x: x.tolist() if isinstance(x, np.ndarray) else list(map(float, str(x).strip('[]').split())))  # converte anche \"[a b]\" in lista\n",
    "\n",
    "for col in ['Gaussian eparams', 'Langauss eparams']:\n",
    "    df[col] = df[col].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "\n",
    "\n",
    "def apply_vis_to_second(lst, vis_val):\n",
    "    new_lst = lst.copy()\n",
    "    if len(new_lst) >= 2 and vis_val is not None:\n",
    "        new_lst[1] = new_lst[1] / (vis_val)\n",
    "    return new_lst\n",
    "\n",
    "# --- 1️⃣ Applica la correzione per la visibilità (già lo fai)\n",
    "for col in ['Gaussian params', 'Langauss params', 'Gaussian eparams', 'Langauss eparams']:\n",
    "    df[f'vis {col}'] = df.apply(lambda row: apply_vis_to_second(row[col], row['vis']), axis=1)\n",
    "\n",
    "# --- 2️⃣ Trova il massimo del secondo elemento di tutte le liste\n",
    "max_second = {}\n",
    "for col in ['Gaussian params', 'Langauss params', 'Gaussian eparams', 'Langauss eparams']:\n",
    "    vis_col = f'vis {col}'\n",
    "    max_val = df[vis_col].apply(lambda x: x[1] if isinstance(x, list) and len(x) > 1 else np.nan).max()\n",
    "    max_second[vis_col] = max_val\n",
    "\n",
    "# --- 3️⃣ Normalizza tutti i secondi elementi rispetto al massimo\n",
    "def normalize_second(lst, max_val):\n",
    "    if isinstance(lst, list) and len(lst) > 1 and max_val not in [0, None, np.nan]:\n",
    "        new_lst = lst.copy()\n",
    "        new_lst[1] = new_lst[1] / max_val\n",
    "        return new_lst\n",
    "    return lst\n",
    "\n",
    "for col in ['Gaussian params', 'Langauss params', 'Gaussian eparams', 'Langauss eparams']:\n",
    "    vis_col = f'vis {col}'\n",
    "    df[f'norm {vis_col}'] = df[vis_col].apply(lambda lst: normalize_second(lst, max_second[vis_col]))\n",
    "\n",
    "# print(df[['Gaussian params','vis','vis Gaussian params']].head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_two_params(df, col, axes, color='red', bins=20, title='Gaussian Fit Analysis'):\n",
    "    intercepts = df[col].apply(str_to_array).apply(lambda x: x[0])\n",
    "    slopes = df[col].apply(str_to_array).apply(lambda x: x[1])\n",
    "\n",
    "    axes[0].hist(intercepts, bins=20, color=color, edgecolor='black')\n",
    "    axes[0].set_xlabel('Intercept [$N_{{PE}}$]')\n",
    "    axes[0].set_ylabel('Counts [AU]')\n",
    "    axes[0].set_title(title + ' - Intercept')\n",
    "\n",
    "    axes[1].hist(slopes, bins=20, color=color, edgecolor='black')\n",
    "    axes[1].set_xlabel('Slope [$N_{{PE}}$/GeV]')\n",
    "    axes[1].set_ylabel('Counts [AU]')\n",
    "    axes[1].set_title(title + ' - Slope')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of linear fit fit info for all channels - GAUSSIAN\n",
    "\n",
    "fig, axes = plt.subplots(3, 2, figsize=(12, 15))\n",
    "\n",
    "plot_two_params(df[df['APA']==1], 'Gaussian params', axes[0], color='#cce5ff', title='APA 1')\n",
    "plot_two_params(df[df['APA']==2], 'Gaussian params', axes[1], color='#6699ff', title='APA 2')\n",
    "plot_two_params(df, 'Gaussian params', axes[2], color='#003399', title='ALLA CHANNELS')\n",
    "\n",
    "fig.suptitle('Gaussian fit', fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{output_folder}/gaussian_params_hist.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of linear fit fit info for all channels - LANGAUSS\n",
    "\n",
    "fig, axes = plt.subplots(3, 2, figsize=(12, 15))\n",
    "\n",
    "plot_two_params(df[df['APA']==1], 'Langauss params', axes[0], color='#ccffcc', title='APA 1')\n",
    "plot_two_params(df[df['APA']==2], 'Langauss params', axes[1], color='#66cc66', title='APA 2')\n",
    "plot_two_params(df, 'Langauss params', axes[2], color='#006600', title='ALLA CHANNELS')\n",
    "\n",
    "fig.suptitle('Langauss fit', fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{output_folder}/langauss_params_hist.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of linear fit fit info for all channels - DIFFERENCE\n",
    "\n",
    "df['diff_params'] = df.apply(\n",
    "    lambda row: [\n",
    "        str_to_array(row['Gaussian params'])[0] - str_to_array(row['Langauss params'])[0],\n",
    "        str_to_array(row['Gaussian params'])[1] - str_to_array(row['Langauss params'])[1]\n",
    "    ],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "fig, axes = plt.subplots(3, 2, figsize=(12, 15))\n",
    "\n",
    "plot_two_params(df[df['APA']==1], 'diff_params', axes[0], color='#ffcce6', title='APA 1')\n",
    "plot_two_params(df[df['APA']==2], 'diff_params', axes[1], color='#ff66b2', title='APA 2')\n",
    "plot_two_params(df, 'diff_params', axes[2], color='#cc0066', title='ALL CHANNELS')\n",
    "\n",
    "fig.suptitle('Params difference', fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{output_folder}/diff_params_hist.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "def plot_apa_final(df, fit_function):\n",
    "    apas_to_plot = [1, 2]\n",
    "    \n",
    "    # Create figure with two subplots\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(20, 12))\n",
    "    \n",
    "    # Calculate global min/max for a consistent color scale\n",
    "    # We use a try-except to avoid crash if some rows are problematic\n",
    "    def get_val_safe(x, idx):\n",
    "        try:\n",
    "            return str_to_array(x)[idx]\n",
    "        except:\n",
    "            return np.nan\n",
    "\n",
    "    all_slopes = df[f'{fit_function} params'].apply(lambda x: get_val_safe(x, 1))\n",
    "    vmin, vmax = all_slopes.min(), all_slopes.max()\n",
    "\n",
    "    for i, apa_id in enumerate(apas_to_plot):\n",
    "        # 1. Create lookup: (Endpoint, Channel) -> (slope, error)\n",
    "        df_apa = df[df['APA'] == apa_id]\n",
    "        lookup = {}\n",
    "        \n",
    "        for _, row in df_apa.iterrows():\n",
    "            try:\n",
    "                params = str_to_array(row[f'{fit_function} params'])\n",
    "                eparams = str_to_array(row[f'{fit_function} eparams'])\n",
    "                lookup[(row['Endpoint'], row['Channel'])] = (params[1], eparams[1])\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        # 2. Initialize matrices for heatmap (colors) and annotations (text)\n",
    "        grid_values = np.full((10, 4), np.nan)\n",
    "        grid_labels = np.full((10, 4), \"\", dtype=object)\n",
    "        \n",
    "        apa_obj = APA_map[apa_id]\n",
    "        \n",
    "        # 3. Fill the grids\n",
    "        for r in range(10):\n",
    "            for c in range(4):\n",
    "                unique_ch = apa_obj.data[r][c]\n",
    "                ep, ch = unique_ch.endpoint, unique_ch.channel\n",
    "                \n",
    "                data_point = lookup.get((ep, ch), None)\n",
    "                \n",
    "                if data_point is not None:\n",
    "                    val, err = data_point\n",
    "                    grid_values[r, c] = val\n",
    "                    grid_labels[r, c] = f\"END: {ep} - CH: {ch}\\nB = ({val:.0f} $\\pm$ {err:.0f}) $\\\\frac{{N_{{PE}}}}{{GeV}}$\"\n",
    "                else:\n",
    "                    grid_labels[r, c] = f\"END: {ep} - CH: {ch}\\nNo data\"\n",
    "\n",
    "        # 4. Draw the Heatmap\n",
    "        sns.heatmap(grid_values, \n",
    "                    annot=grid_labels, \n",
    "                    fmt=\"\", \n",
    "                    cmap=\"YlOrRd\", \n",
    "                    ax=axes[i],\n",
    "                    linewidths=1,\n",
    "                    linecolor='black',\n",
    "                    vmin=vmin, \n",
    "                    vmax=vmax,\n",
    "                    cbar_kws={'label': 'Gaussian Slope Value'})\n",
    "        \n",
    "        axes[i].set_title(f\"APA {apa_id} - {fit_function} fit\", fontsize=18, fontweight='bold', pad=20)\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{output_folder}/{fit_function}_hitmap.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of linear fit slope for all channels - GAUSSIAN\n",
    "plot_apa_final(df, 'Gaussian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of linear fit slope for all channels - LANGAUSS\n",
    "plot_apa_final(df, 'Langauss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_apa_final(df, 'vis Langauss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_apa_final(df, 'norm vis Langauss')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "waffles_NEW",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
